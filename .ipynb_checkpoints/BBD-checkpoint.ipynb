{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3aeeead0-7966-4bb3-b37a-31c49f92817b",
   "metadata": {},
   "source": [
    "###  Most Common Tweets at Location and Given Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302b19ba-b2a0-4ddc-9fb1-99b0b8e2f17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import snscrape.modules.twitter as snstwitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f19f8c-4f49-476f-993d-f1372168c693",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Twitter:\n",
    "    def __init__(self):\n",
    "        self.feed_tweets = []\n",
    "        self.trendy_feed = []\n",
    "    \n",
    "    def feed(self,search_item,place,n_tweets):\n",
    "        scrapper = snstwitter.TwitterSearchScraper(f'{search_item} near:\"{place}\" within:100km')\n",
    "        tweets = []\n",
    "        for i,tweet in enumerate(scrapper.get_items()):\n",
    "            data = [\n",
    "            tweet.date,\n",
    "            tweet.content,\n",
    "            tweet.user.username,\n",
    "            tweet.likeCount,\n",
    "            tweet.retweetCount\n",
    "            search_item\n",
    "            ]\n",
    "            tweets.append(data)\n",
    "            if i >n_tweets:\n",
    "                break\n",
    "                \n",
    "        return tweets\n",
    "    \n",
    "    \n",
    "    def trendyFeed(self,place,n_tweets):\n",
    "        tweets = []\n",
    "        feed = snstwitter.TwitterTrendsScraper()\n",
    "        self.trendy_feed=feed\n",
    "        for trend in feed:\n",
    "            trend = self.feed(trend.name,place,n_tweets)\n",
    "            for tweet_raw in trend:\n",
    "                tweets.append(tweet_raw)\n",
    "        return tweets\n",
    "    \n",
    "    \n",
    "    def getTrendyTweets(self,place,n_tweets):\n",
    "        tweets = self.trendy(place,n_tweets)\n",
    "        return pd.DataFrame(tweets,columns=['date','content','username','likeCount','retweetCount','trend'])\n",
    "    \n",
    "    def getSearchedTweets(self,search_item,place,n_tweets):\n",
    "        tweets = self.feed(search_item,place,n_tweets)\n",
    "        return pd.DataFrame(tweets,columns=['date','content','username','likeCount','retweetCount','trend'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "852027de-5be3-49cb-86fe-478bd26c8884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#يوم_الترويه\n",
      "منتخب السويس\n",
      "سيف جعفر\n",
      "#استعد_للعيد_مع_يونس\n",
      "روسيا\n",
      "وائل غنيم\n",
      "حسين الشحات\n",
      "#السيسي_عمرها\n",
      "الاقدار السعيده\n",
      "العطش الاكبر\n",
      "#فاغنر\n",
      "#الكيمياء\n",
      "اليوم الاثنين\n",
      "26 يونيو 2023\n",
      "مصطفي عسل\n",
      "عيد سعيد\n",
      "رامي ربيعة\n",
      "فاروق جعفر\n",
      "نجلاء فتحي\n",
      "بوتين\n"
     ]
    }
   ],
   "source": [
    "feed = snstwitter.TwitterTrendsScraper()\n",
    "for i,x in enumerate(feed.get_items()):\n",
    "    print(x.name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3b0b1935-2adf-4162-9f3e-8e7a0ee054d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trend(name='بوتين', domainContext='Trending', metaDescription='45.9K Tweets')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58b9fac-ff8e-427d-92f3-8cb19ab69dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter = Twitter()\n",
    "twitter_df = twitter.feed(\"wegz\",\"cairo\",100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a8dd4d-f8dd-463b-b9f4-fb4f511ea8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1867e6-62a3-4e21-9d40-7042992136d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download([\n",
    "\"names\",\n",
    "\"stopwords\",\n",
    "\"state_union\",\n",
    "\"twitter_samples\",\n",
    "\"movie_reviews\",\n",
    "\"averaged_perceptron_tagger\",\n",
    "\"vader_lexicon\",\n",
    "\"punkt\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841daa5b-211a-4904-9b6d-06f7f2be0b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "twitter_df_corpus = ''.join(twitter_df['content'])\n",
    "twitter_df_corpus = re.sub(r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", twitter_df_corpus)\n",
    "\n",
    "# Remove English Stop Words \n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "words = [w for w in twitter_df_corpus if w.lower() not in stopwords]\n",
    "\n",
    "#Remove Arabic Stop Wodrs \n",
    "stopwords = nltk.corpus.stopwords.words(\"arabic\")\n",
    "words = [w for w in words if w.lower() not in stopwords]\n",
    "\n",
    "\n",
    "#twitter_df_corpus = ''.join(twitter_df_corpus)\n",
    "words: list[str] = nltk.word_tokenize(twitter_df_corpus)\n",
    "fd = nltk.FreqDist(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41712056-015a-4f84-b0f0-31b7dc76d71d",
   "metadata": {},
   "source": [
    "### 2 - Most Common  Word in Tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b775f2-aaee-4dd7-83d8-3796ab371ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fd.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8ce465-fbe9-42e8-b67c-72108e0f19d1",
   "metadata": {},
   "source": [
    "\n",
    "### 3 - Most Common  Tri-Sentence in Tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c7e12f-574a-4866-bab3-d4808cc725fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "finder = nltk.collocations.TrigramCollocationFinder.from_words(words)\n",
    "finder.ngram_fd.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0051bb-1b5e-4bc3-82c4-571a3db629a4",
   "metadata": {},
   "source": [
    "### 4- Sentiment Analysis For each tweets compunded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6402ef-06f8-4d78-9572-20bc8de82b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "sia_dict = {'positive':0,'neatral':0,'negative':0,'total':0}\n",
    "for tweet in twitter_df.content:\n",
    "    sia_x = sia.polarity_scores(tweet)\n",
    "    sia_dict['positive'] += sia_x['pos']  \n",
    "    sia_dict['negative'] += sia_x['neg'] \n",
    "    sia_dict['neatral'] += sia_x['neu'] \n",
    "    sia_dict['total'] += 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c3567e-bc26-4785-9b9c-d3be13a6ee02",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462fee5a-ce43-4ee6-be12-7b95e7fba66b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
